{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between off-target efficiencies and on-pred, off-pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_Exist_file(path):\n",
    "    import os\n",
    "    if os.path.exists(path):\n",
    "        os.remove(path)\n",
    "\n",
    "\n",
    "def mkdir(path):\n",
    "    import os\n",
    "    path = path.strip() \n",
    "    path = path.rstrip(\"\\\\\") \n",
    "    isExists = os.path.exists(path) \n",
    "    if not isExists:\n",
    "        os.makedirs(path) \n",
    "        print(path + ' 创建成功')\n",
    "    else:\n",
    "        print(path + ' 目录已存在')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## correlation between off-target efficiencies and on, off-prediction efficiencies\n",
    "def get_corr_data_between_ot_and_of(df):\n",
    "    df1 = df.loc[df['core_mismatch_num']==1, :]\n",
    "    df1.reset_index(drop=True, inplace=True)\n",
    "    df1['X'] = df1['new_mutation'].apply(lambda x: x.split('+')[0])\n",
    "    df1['Y'] = df1['new_mutation'].apply(lambda x: x.split('+')[1])\n",
    "    df1['Z'] = df1['new_mutation'].apply(lambda x: x.split('+')[2])\n",
    "    df1['Y_position'] = df1['Y'].apply(lambda x: x.split(\"_\")[0])\n",
    "    stat_dict = {\"position\": [], \"substitution\": [], \"sgRNA_n\": [], \"pearson-on_pred\": [], \"spearman-on_pred\": [], \n",
    "                \"pearson-off_pred\": [], \"spearman-off_pred\": []}\n",
    "    for i in range(21, 44):\n",
    "        pos = 'Y%s:%sM'%(i, i)\n",
    "        temp = df1.loc[df1['Y_position']==pos, :]\n",
    "        for tp in temp['Y'].unique():\n",
    "            temp1 = temp.loc[temp['Y']==tp, :]\n",
    "            on_pear = temp1['RW_off-target_eff'].corr(temp1['on_pred'], method='pearson')\n",
    "            on_spear = temp1['RW_off-target_eff'].corr(temp1['on_pred'], method='spearman')\n",
    "            off_pear = temp1['RW_off-target_eff'].corr(temp1['off_pred'], method='pearson')\n",
    "            off_spear = temp1['RW_off-target_eff'].corr(temp1['off_pred'], method='spearman')\n",
    "            sgRNA_n = len(list(temp1['sgRNA_name'].unique()))\n",
    "            temp1_n = temp1.shape[0]\n",
    "            stat_dict['position'].append(i)\n",
    "            stat_dict['substitution'].append(tp)\n",
    "            stat_dict['sgRNA_n'].append(sgRNA_n)\n",
    "            stat_dict['pearson-on_pred'].append(on_pear)\n",
    "            stat_dict['spearman-on_pred'].append(on_spear)\n",
    "            stat_dict['pearson-off_pred'].append(off_pear)\n",
    "            stat_dict['spearman-off_pred'].append(off_spear)\n",
    "    ## DataFrame\n",
    "    stat_data = pd.DataFrame(stat_dict)\n",
    "    stat_data['substitution'] = stat_data['substitution'].apply(lambda x: x.split('_')[1])\n",
    "    return stat_data\n",
    "\n",
    "\n",
    "def compute_mismatch_num(seq1, seq2):\n",
    "    mis_num = 0\n",
    "    for i, nucle0 in enumerate(seq1):\n",
    "        nucle1 = seq2[i]\n",
    "        if nucle0 != nucle1:\n",
    "            mis_num += 1\n",
    "        else:\n",
    "            pass\n",
    "    return mis_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot correlation\n",
    "def plot_correlation_between_on_and_off(stat_data, save_dir, label='pearson-off_pred'):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    # 设置默认绘图风格\n",
    "    plt.style.use(\"seaborn-white\")\n",
    "    fig, ax = plt.subplots(1,1, figsize=(12, 6))\n",
    "\n",
    "    label_dict = {'pearson-on_pred': 'Pearson correlation', \n",
    "                  'pearson-off_pred': 'Pearson correlation', \n",
    "                  'spearman-on_pred': 'Spearman correlation', \n",
    "                  'spearman-off_pred': 'Spearman correlation'}\n",
    "    order = [i for i in range(21, 44)]\n",
    "    ax = sns.boxplot(x='position', y=label, data=stat_data, width=0.4, color='white', \n",
    "                     fliersize=0.5, linewidth=0.5, order=order)\n",
    "    ## 坐标轴不可见\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax = sns.stripplot(x='position', y=label, hue='substitution', data=stat_data, \n",
    "                       jitter=0.1, size=3, order=order)\n",
    "    ## xlabel, ylabel\n",
    "    plt.ylabel(label_dict[label], fontsize=12, weight='bold')\n",
    "    plt.xlabel(\"Target + PAM Position\", fontsize=12, weight='bold')\n",
    "    ## xticks\n",
    "    xticks = list(range(1, 21, 1)) + ['N', 'G', 'G', '', '']\n",
    "    plt.xticks(range(len(xticks)), xticks, fontsize=10, weight='bold')\n",
    "    ## ylim\n",
    "    plt.ylim(0, 1.)\n",
    "    title = '%s between off-target efficiencies \\nand on-target predicited efficiencies of target sequence'%(label_dict[label])\n",
    "    plt.title(title, fontsize=12, weight='bold')\n",
    "    savefig_path = save_dir + '/%s with off-target.%s'%(label, figsuplix)\n",
    "    plt.savefig(savefig_path, dpi=300, bbox_inches = 'tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = \"../data\"\n",
    "os.chdir(main_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./pdf/off-target/Fig29-correlation between on-pred and off 目录已存在\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'stats'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-da5671a10fd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m## plot data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'pearson-off_pred'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mplot_correlation_between_on_and_off\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstat_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'pearson-on_pred'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-fddad979cbaa>\u001b[0m in \u001b[0;36mplot_correlation_between_on_and_off\u001b[0;34m(stat_data, save_dir, label)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_correlation_between_on_and_off\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstat_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pearson-off_pred'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# 设置默认绘图风格\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python36/lib/python3.6/site-packages/seaborn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import seaborn objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mrcmod\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F401,F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F401,F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpalettes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F401,F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mrelational\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F401,F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python36/lib/python3.6/site-packages/seaborn/rcmod.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcycler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcycler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpalettes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python36/lib/python3.6/site-packages/seaborn/palettes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexternal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhusl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdesaturate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_color_cycle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxkcd_rgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrayons\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python36/lib/python3.6/site-packages/seaborn/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'stats'"
     ]
    }
   ],
   "source": [
    "## Correlation between off-target efficiencies and on-pred, off-pred\n",
    "data_dir = \"./Off-Target/correlation between on-pred and off\"\n",
    "stat_data = pd.read_csv(data_dir + \"/correlation between on-pred and off for anlysis of off-target.csv\")\n",
    "\n",
    "figsuplix = \"pdf\"\n",
    "save_dir = './%s/off-target/Fig29-correlation between on-pred and off'%figsuplix\n",
    "mkdir(save_dir)\n",
    "## plot data \n",
    "label = 'pearson-off_pred'\n",
    "plot_correlation_between_on_and_off(stat_data, save_dir, label)\n",
    "## \n",
    "label = 'pearson-on_pred'\n",
    "mkdir(save_dir)\n",
    "plot_correlation_between_on_and_off(stat_data, save_dir, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance of Elastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 基础模块 1\n",
    "def is_Exist_file(path):\n",
    "    import os\n",
    "    if os.path.exists(path):\n",
    "        os.remove(path)\n",
    "\n",
    "\n",
    "def mkdir(path):\n",
    "    import os\n",
    "    path = path.strip() \n",
    "    path = path.rstrip(\"\\\\\")\n",
    "    isExists = os.path.exists(path) \n",
    "    if not isExists:\n",
    "        os.makedirs(path) \n",
    "        print(path + ' 创建成功')\n",
    "    else:\n",
    "        print(path + ' 目录已存在') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Note_off_target_all_PM():\n",
    "    ## feature noting\n",
    "    feat_dict = {}\n",
    "    ## for offSeq feature\n",
    "    c = 0\n",
    "    for i in range(23):\n",
    "        for nucle in ['A', 'G', 'C', 'T']:\n",
    "            c += 1\n",
    "            feat_dict['offSeq_%s'%(c)] = 'offSeq_%s%s'%(i + 1, nucle)\n",
    "    ## for gRNASeq feature\n",
    "    c = 0\n",
    "    for i in range(23):\n",
    "        for nucle in ['A', 'G', 'C', 'T']:\n",
    "            c += 1\n",
    "            feat_dict['gRNASeq_%s'%(c)] = 'gRNASeq_%s%s'%(i + 1, nucle)\n",
    "    ## for PAM\n",
    "    pam_feats = ['GG', 'AG', 'GT', 'GC', 'GA', 'TG', 'CG', 'other']\n",
    "    for i, pam in enumerate(pam_feats):\n",
    "        feat_dict['+P_%s'%(i+1)] = 'PAM-%s' % (pam)\n",
    "    ## for mismatch_num feature\n",
    "    feat_dict['mismatch_num_region_1'] = 'up_mismatch_number'\n",
    "    feat_dict['mismatch_num_region_2'] = 'target_mismatch_number'\n",
    "    feat_dict['mismatch_num_region_3'] = 'down_mismatch_number'\n",
    "    ## for on-off predict feature\n",
    "    feat_dict['pred_feat_1'] = 'on_pred_feat'\n",
    "    feat_dict['pred_feat_2'] = 'off_pred_feat'\n",
    "    ## for +mismatch feature\n",
    "    align_order = ['AC', 'AG', 'AT', 'CA', 'CG', 'CT', 'GA', 'GC', 'GT', 'TA', 'TC', 'TG']\n",
    "    c = 0\n",
    "    for i in range(23):\n",
    "        for one_p in align_order:\n",
    "            c += 1\n",
    "            feat_dict['+M_%s'%(c)] = 'mismatch_pt_%s%s'%(i + 1, one_p)\n",
    "    return feat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 计算变异系数：coefficient of variation\n",
    "def compute_coefficient_variation(data, col):\n",
    "    f = data['f'].tolist()[0]\n",
    "    if (f == 'mismatch_pt_22') or (f == 'mismatch_pt_23'):\n",
    "        temp = data.loc[data[col]!=0, :]\n",
    "    else:\n",
    "        temp = data\n",
    "    import numpy as np\n",
    "    min_v = temp[col].min()\n",
    "    array_0 = np.array(temp[col] + abs(min_v))\n",
    "    cv = np.std(array_0, ddof=0)/np.mean(array_0)\n",
    "    ## weight substract between max_v and min_v\n",
    "    max_v = temp[col].max()\n",
    "    data['coeff of variation'] = cv\n",
    "    data['extreme diff'] = max_v - min_v\n",
    "    data['max_abs'] = max([abs(max_v), abs(min_v)])\n",
    "    return data\n",
    "\n",
    "\n",
    "## get plot stat data\n",
    "def get_plot_integrated_value(feat_data, elastic):\n",
    "    elastic_importance = elastic.coef_\n",
    "    ## \n",
    "    model_col = 'K562_Elastic_coef'\n",
    "    feat_data[model_col] = elastic_importance\n",
    "    feat_data['abs_elastic'] = feat_data[model_col].apply(lambda x: abs(x))\n",
    "    feat_data['f'] = feat_data['feat_label'].apply(lambda x: \"_\".join(x.split(\"_\")[:-1]))\n",
    "    ## for mismatch position AND type\n",
    "    ##########################################\n",
    "    ## compute_coefficient_variation\n",
    "    mdata = feat_data.loc[feat_data['f']=='mismatch_pt', :]\n",
    "    mdata['f'] = mdata['feat_label'].apply(lambda x: x[:-2])\n",
    "    sdata = mdata.groupby('f').apply(lambda data: compute_coefficient_variation(data, model_col))\n",
    "    print(sdata.shape)\n",
    "    ##  计算 integrated_value\n",
    "    sdata = sdata[['f', 'coeff of variation', 'extreme diff', 'max_abs']]\n",
    "    sdata.drop_duplicates(inplace=True)\n",
    "    sdata['x'] = sdata['f'].apply(lambda x: int(x.split(\"_\")[-1]))\n",
    "    sdata.sort_values(by='x', ascending=True, inplace=True)\n",
    "    sdata['integrated_value'] = sdata.apply(lambda row: row['max_abs']*row['coeff of variation'], axis=1)\n",
    "    return feat_data, sdata\n",
    "\n",
    "\n",
    "## plot Weight_Difference\n",
    "## For 每个位置的权重差\n",
    "def plot_weight_difference(sdata, save_dir, model_col='K562_Elastic_coef'):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt \n",
    "\n",
    "    plt.figure(figsize=(8,4))\n",
    "    xticks = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 'N', 'G', 'G']\n",
    "\n",
    "    plt.plot(sdata['x'].tolist(), sdata['extreme diff'].tolist(), 'o-', color='g', label=\"weight diff\") # o-:圆形\n",
    "    plt.xticks(np.array(range(23)) + 1, xticks, weight='bold')\n",
    "    plt.xlabel(\"Mismatch Position\", weight='bold')#横坐标名字\n",
    "    plt.ylabel(\"Weight Difference\", weight='bold')#纵坐标名字\n",
    "    # plt.legend(loc = \"best\")#图例\n",
    "    savefig_path = save_dir + '/%s_feature_importance_for_K562_all+P+M_by_Weight_Diff.%s'%(model_col, figsuplix)\n",
    "    plt.savefig(savefig_path, dpi=300, bbox_inches = 'tight')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "##\n",
    "## For 每个位置的变异系数\n",
    "def plot_coefficient_of_variation(sdata, save_dir, model_col='K562_Elastic_coef'):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt \n",
    "\n",
    "    plt.figure(figsize=(8,4))\n",
    "    xticks = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 'N', 'G', 'G']\n",
    "    plt.plot(sdata['x'].tolist(), sdata['coeff of variation'].tolist(), 'o-', color='g', label=\"weight diff\") # o-:圆形\n",
    "    plt.xticks(np.array(range(23)) + 1, xticks, weight='bold')\n",
    "    plt.xlabel(\"Mismatch Position\", weight='bold')\n",
    "    plt.ylabel(\"Coefficient of variation\", weight='bold')\n",
    "    savefig_path = save_dir + '/%s_feature_importance_for_K562_all+M_by_Coefficient_of_Variation.%s'%(model_col, figsuplix)\n",
    "    plt.savefig(savefig_path, dpi=300, bbox_inches = 'tight')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "## For 每个位置的最大权重值\n",
    "def plot_max_weight(sdata, save_dir, model_col='K562_Elastic_coef'):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt \n",
    "    plt.figure(figsize=(8,4))\n",
    "    xticks = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 'N', 'G', 'G']\n",
    "    plt.plot(sdata['x'].tolist(), sdata['max_abs'].tolist(), 's-', color='r', label=\"weight diff\") # o-:圆形\n",
    "    plt.xticks(np.array(range(23)) + 1, xticks, weight='bold')\n",
    "    plt.xlabel(\"Mismatch Position\", weight='bold')\n",
    "    plt.ylabel(\"Max weigth absolute value\", weight='bold')\n",
    "    savefig_path = save_dir + '/%s_feature_importance_for_K562_all+P+M_by_Max_Weight.%s'%(model_col, figsuplix)\n",
    "    plt.savefig(savefig_path, dpi=300, bbox_inches = 'tight')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "##\n",
    "## 整合 weigth value & coefficient of variation\n",
    "def plot_integrated_value(sdata, save_dir, model_col='K562_Elastic_coef'):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt \n",
    "    plt.figure(figsize=(8,4))\n",
    "    xticks = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 'N', 'G', 'G']\n",
    "    plt.plot(sdata['x'].tolist(), sdata['integrated_value'].tolist(), 's-', color='b', label=\"weight diff\") # o-:圆形\n",
    "    plt.xticks(np.array(range(23)) + 1, xticks, weight='bold')\n",
    "    plt.xlabel(\"Mismatch Position\", weight='bold')\n",
    "    plt.ylabel(\"Integrated value \\n(weigth * coefficient of variation)\", weight='bold')\n",
    "    savefig_path = save_dir + '/%s_feature_importance_for_K562_all+P+M_by_Integrated_value.%s'%(model_col, figsuplix)\n",
    "    plt.savefig(savefig_path, dpi=300, bbox_inches = 'tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.linear_model.coordinate_descent'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[1;32m      4\u001b[0m elastic_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Off-Target/Feature_importance/K562-200_Elastic-all+P+M_count-24.model\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m elastic \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43melastic_model_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m## get plot data\u001b[39;00m\n\u001b[1;32m      7\u001b[0m feat_data, sdata \u001b[38;5;241m=\u001b[39m get_plot_integrated_value(feat_data, elastic)\n",
      "File \u001b[0;32m~/opt/miniforge3/envs/python38/lib/python3.8/site-packages/joblib/numpy_pickle.py:587\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    582\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    583\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    584\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n\u001b[1;32m    585\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[0;32m--> 587\u001b[0m             obj \u001b[38;5;241m=\u001b[39m \u001b[43m_unpickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmmap_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m~/opt/miniforge3/envs/python38/lib/python3.8/site-packages/joblib/numpy_pickle.py:506\u001b[0m, in \u001b[0;36m_unpickle\u001b[0;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    504\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 506\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m unpickler\u001b[38;5;241m.\u001b[39mcompat_mode:\n\u001b[1;32m    508\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has been generated with a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    509\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoblib version less than 0.10. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    510\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease regenerate this pickle file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    511\u001b[0m                       \u001b[38;5;241m%\u001b[39m filename,\n\u001b[1;32m    512\u001b[0m                       \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[0;32m~/opt/miniforge3/envs/python38/lib/python3.8/pickle.py:1212\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1210\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[0;32m-> 1212\u001b[0m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[0;32m~/opt/miniforge3/envs/python38/lib/python3.8/pickle.py:1528\u001b[0m, in \u001b[0;36m_Unpickler.load_global\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1526\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreadline()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1527\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreadline()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1528\u001b[0m klass \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend(klass)\n",
      "File \u001b[0;32m~/opt/miniforge3/envs/python38/lib/python3.8/pickle.py:1579\u001b[0m, in \u001b[0;36m_Unpickler.find_class\u001b[0;34m(self, module, name)\u001b[0m\n\u001b[1;32m   1577\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m _compat_pickle\u001b[38;5;241m.\u001b[39mIMPORT_MAPPING:\n\u001b[1;32m   1578\u001b[0m         module \u001b[38;5;241m=\u001b[39m _compat_pickle\u001b[38;5;241m.\u001b[39mIMPORT_MAPPING[module]\n\u001b[0;32m-> 1579\u001b[0m \u001b[38;5;28;43m__import__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproto \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m   1581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _getattribute(sys\u001b[38;5;241m.\u001b[39mmodules[module], name)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.linear_model.coordinate_descent'"
     ]
    }
   ],
   "source": [
    "## feature noting\n",
    "feat_data = pd.read_excel('./Off-Target/Feature_importance/feature_noting.xlsx')\n",
    "import joblib\n",
    "elastic_model_path = './Off-Target/Feature_importance/K562-200_Elastic-all+P+M_count-24.model'\n",
    "elastic = joblib.load(elastic_model_path)\n",
    "## get plot data\n",
    "feat_data, sdata = get_plot_integrated_value(feat_data, elastic)\n",
    "\n",
    "## plot\n",
    "model_col = 'K562_Elastic_coef'\n",
    "# save_dir = './Feature_importance'\n",
    "save_dir = './%s/off-target/Fig31-32-integrated value'%figsuplix\n",
    "mkdir(save_dir)\n",
    "## For 每个位置的权重差\n",
    "plot_weight_difference(sdata, save_dir, model_col)\n",
    "## For 每个位置的变异系数\n",
    "plot_coefficient_of_variation(sdata, save_dir, model_col)\n",
    "## For 每个位置的最大权重值\n",
    "plot_max_weight(sdata, save_dir, model_col)\n",
    "## 整合 weigth value & coefficient of variation\n",
    "plot_integrated_value(sdata, save_dir, model_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python36]",
   "language": "python",
   "name": "conda-env-python36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
